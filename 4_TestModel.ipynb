{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script loads the tflite model and uses it on a bunch of images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is your labels you'v defined in 2_doAnnotations\n",
    "LABELS =[\"Briller\"]\n",
    "#LABELS = ['Membran_Mangler','Stort_Tape','Lille_Tape','Kul_Mangler',]\n",
    "paths ={\n",
    "\"PRE_TRAINED_MODEL\" :  os.path.join('model','detect.tflite'),# this model is trained with 10 images and 4000 steps\n",
    "\"HOME_MADE_MODEL\" : os.path.join('Tensorflow','workspace','models','my_ssd_mobnet','tfliteexport','saved_model','detect.tflite'),\n",
    "'VALIDATION_PATH':os.path.join('Images','Validation')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __set_input_tensor__(image,interpreter):\n",
    "    \"\"\"Sets the input tensor.\"\"\"\n",
    "    tensor_index = interpreter.get_input_details()[0]['index']\n",
    "    input_tensor = interpreter.tensor(tensor_index)()[0]\n",
    "    input_tensor[:, :] = np.expand_dims((image - 255) / 255, axis=0)\n",
    "\n",
    "def __get_output_tensor__(index,interpreter):\n",
    "    \"\"\"Returns the output tensor at the given index.\"\"\"\n",
    "    output_details = interpreter.get_output_details()[index]\n",
    "    tensor = np.squeeze(\n",
    "        interpreter.get_tensor(output_details['index']))\n",
    "    return tensor\n",
    "def __generate_dataframe__(scores, boxes, count, classes, threshold=0.8):\n",
    "        ''' Function to generate a dataframe in the expected format by the tensorflow algorithm\n",
    "            scores : array of prediction scores between 0 and 1\n",
    "            boxes  : array with coordinates representing the bounding box, in a format between 0 and 1 compared to the  full image\n",
    "            classes : array of classes indicated what is to what \n",
    "            threshold : float between 0 and 1 indicating how confidant we want to be\n",
    "        '''\n",
    "        results = []\n",
    "        for i in range(count):\n",
    "            if scores[i] >= threshold:\n",
    "                result = {\n",
    "                    'bounding_box': boxes[i],\n",
    "                    'class_id': classes[i],\n",
    "                    'score': scores[i]\n",
    "                }\n",
    "                results.append(result)\n",
    "        return results\n",
    "def __get_true_bounding_box__(result, camera_height, camera_width, scaling):\n",
    "        ''' CAMERA_HEIGHT & CAMERA_WIDTH is the frame size in the X&Y direction, 800x600 \n",
    "            result is the result of the tensorflow detection algoritme\n",
    "            We expect an list containing a bounding_box as key with an np.array with the four corners \n",
    "        '''\n",
    "        ymin, xmin, ymax, xmax = result['bounding_box']\n",
    "        xmin = int(max(1, xmin * camera_width) * scaling)\n",
    "        xmax = int(min(camera_width, xmax * camera_width) * scaling)\n",
    "        ymin = int(max(1, ymin * camera_height) * scaling)\n",
    "        ymax = int(min(camera_height, ymax * camera_height) * scaling)\n",
    "        return ymin, xmin, ymax, xmax\n",
    "def detect_objects(frame,interpreter, threshold=0.8):\n",
    "        \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
    "        TENSORFLOW_MODEL_SIZE=(320, 320)\n",
    "        # pylint: disable=no-member\n",
    "        image = cv.resize(frame, TENSORFLOW_MODEL_SIZE)\n",
    "        __set_input_tensor__(image,interpreter)\n",
    "        interpreter.invoke()\n",
    "        # Get all output details\n",
    "        scores =__get_output_tensor__(0,interpreter)\n",
    "        boxes = __get_output_tensor__(1,interpreter)\n",
    "        count = __get_output_tensor__(2,interpreter).astype(int)\n",
    "        classes = __get_output_tensor__(3,interpreter).astype(int)\n",
    "        return __generate_dataframe__(scores, boxes, count, classes,\n",
    "                                             threshold)\n",
    "def draw_rectangle(frame, res,labels,image_size):\n",
    "        ''' draw the found bounding box detected from self.detect_objects '''\n",
    "        for result in res:\n",
    "            (ymin, xmin, ymax, xmax) = __get_true_bounding_box__(result,image_size[0], image_size[1],1)\n",
    "            # pylint: disable=no-member\n",
    "            cv.rectangle(frame, (xmin, ymin), (xmax, ymax),\n",
    "                            (0,0,255), 3)\n",
    "            # pylint: disable=no-member\n",
    "            cv.putText(frame, labels[result['class_id']],\n",
    "                       (xmin, ymax),\n",
    "                        cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2,\n",
    "                        cv.LINE_AA)\n",
    "            \n",
    "        return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your model!\n",
    "In the next part we are using your model for detecting an object in the image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "#MODEL_TO_USE = paths['HOME_MADE_MODEL']\n",
    "MODEL_TO_USE = paths['PRE_TRAINED_MODEL']\n",
    "print(\"We are using the following model <\",MODEL_TO_USE,\">\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your model on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=MODEL_TO_USE)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "#using interactive mode\n",
    "#%matplotlib tk\n",
    "\n",
    "# create a webcam object and read the image\n",
    "webcam = cv.VideoCapture(0)\n",
    "# make the webcam only show the latest image\n",
    "webcam.set(cv.CAP_PROP_BUFFERSIZE, 1)\n",
    "# read the image\n",
    "_,img = webcam.read()\n",
    "# print image size\n",
    "image_size = img.shape\n",
    "print(image_size)\n",
    "# release the webcam\n",
    "webcam.release()\n",
    "# detect the objects\n",
    "res = detect_objects(img,interpreter, threshold=0.9)\n",
    "# draw the bounding box\n",
    "drawing = draw_rectangle(img,res,LABELS,image_size)\n",
    "# show the image\n",
    "plt.figure(num=1,figsize=(10,10))\n",
    "plt.imshow(cv.cvtColor(drawing, cv.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=MODEL_TO_USE)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# create a webcam object and read the image\n",
    "webcam = cv.VideoCapture(0)\n",
    "# make the webcam only show the latest image\n",
    "webcam.set(cv.CAP_PROP_BUFFERSIZE, 1)\n",
    "# read 10 images\n",
    "for i in range(10):\n",
    "    _,img = webcam.read()\n",
    "    # print image size\n",
    "    image_size = img.shape\n",
    "    print(image_size)\n",
    "\n",
    "    # detect the objects\n",
    "    res = detect_objects(img,interpreter, threshold=0.9)\n",
    "    # draw the bounding box\n",
    "    drawing = draw_rectangle(img,res,LABELS,image_size)\n",
    "    # show the image\n",
    "    plt.figure(num=1,figsize=(10,10))\n",
    "    plt.imshow(cv.cvtColor(drawing, cv.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    # wait 3 seconds\n",
    "    time.sleep(3)\n",
    "\n",
    "# release the webcam\n",
    "webcam.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b483f96187fd6e303e666ef9481cbbb573d1c50aa2dd08f4df5af960371a864e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('idf4.3_py3.9_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
